{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 4b: Support Vector Machine Regressor\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "This notebook includes the same regression problem of Workshop 4a, but in this case we use a more flexible (and likely powerful) [Support Vector Regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) regression technique, which is based on Support Vector Machines (SVM).\n",
    "\n",
    "Usually SVM are used for classification stasks, this [post](https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2) explains how they can be used for regression. You should also read [section 1.4.2 of the scikitlearn SVM page](http://scikit-learn.org/stable/modules/svm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "#ms.use(\"seaborn-v0_8\") \n",
    "import IPython.display as Ipd\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sr = 22050\n",
    "\n",
    "#Instead of writing the code to extract the features and target value we define a function,\n",
    "#which is more elegant, it's reusable (shorter code) and makes the following code more readable.\n",
    "#For practicality, the vector features are flattenedm so that that can be stored on a row of a N-dim array\n",
    "\n",
    "#Mind that the file name is not important here because there is no label to consider (as in the previous examples)\n",
    "\n",
    "def extract_features_targets(filename, sr=sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    \n",
    "    features = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    target = np.mean(librosa.feature.rms(y=signal))\n",
    "    \n",
    "    return features, target\n",
    "\n",
    "\n",
    "#creating an array of zeros of the proper size where we will store computed features and lables\n",
    "filenames = os.listdir('./data/examples3')\n",
    "\n",
    "#to set the right number of columns, we call the extract_features_target() function and get the size of the features\n",
    "num_of_features = extract_features_targets('./data/examples3/'+filenames[0], sr=sr)[0].size\n",
    "num_of_targets = extract_features_targets('./data/examples3/'+filenames[0], sr=sr)[1].size\n",
    "features = np.zeros((len(filenames),num_of_features)) \n",
    "targets = np.zeros((len(filenames),num_of_targets))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    #print('processing',filenames[i])\n",
    "    features[i,:], targets[i,:] = extract_features_targets('./data/examples3/'+filenames[i], sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step converts the targets from a numpy array to \n",
    "#a Pandas series, which allows backtracing poorly performing examples\n",
    "#scikitlearn can handle features or targets also as Pandas formats\n",
    "#mind that this wont work with multiple target values (as the data must be dimensionless)\n",
    "targets = pd.Series(targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset in training and testing parts\n",
    "feat_train, feat_test, tar_train, tar_test = train_test_split(features, targets, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, training and testing the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Create SVR regression object\n",
    "regr = SVR(C=1.0, epsilon=0.001, kernel='rbf')\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(feat_train, tar_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "tar_predict = regr.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.0006\n",
      "Mean absolute error: 0.0172\n",
      "Max error squared error: 0.0653\n",
      "Median absolute error: 0.0105\n",
      "Coefficient of determination (R2 score): 0.8763\n",
      "Explained variance score: 0.8845\n"
     ]
    }
   ],
   "source": [
    "#computing a set of performance metrics\n",
    "\n",
    "#mean squared error (lower the better)\n",
    "print('Mean squared error: %.4f'% sklearn.metrics.mean_squared_error(tar_test, tar_predict))\n",
    "\n",
    "#mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% sklearn.metrics.mean_absolute_error(tar_test, tar_predict))\n",
    "\n",
    "#maximum error (lower the better)\n",
    "print('Max error squared error: %.4f'% sklearn.metrics.max_error(tar_test, tar_predict))\n",
    "\n",
    "#median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% sklearn.metrics.median_absolute_error(tar_test, tar_predict))\n",
    "\n",
    "#coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% sklearn.metrics.r2_score(tar_test, tar_predict))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% sklearn.metrics.explained_variance_score(tar_test, tar_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying errors and files with error above a given treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    0.002810\n",
      "37    0.015772\n",
      "57    0.008701\n",
      "60    0.033411\n",
      "77    0.007677\n",
      "20    0.010369\n",
      "10    0.010529\n",
      "48    0.000822\n",
      "34    0.015369\n",
      "28    0.001484\n",
      "49    0.037888\n",
      "32    0.001150\n",
      "17    0.032080\n",
      "22    0.030327\n",
      "23    0.012609\n",
      "24    0.001281\n",
      "12    0.003423\n",
      "63    0.009125\n",
      "85    0.036609\n",
      "43    0.001306\n",
      "35    0.039637\n",
      "13    0.004674\n",
      "54    0.010780\n",
      "74    0.034132\n",
      "55    0.001342\n",
      "89    0.065312\n",
      "6     0.034946\n",
      "dtype: float64\n",
      "test examples above the error_threshold\n",
      "mallet_acoustic_062-096-050.wav 0.015771913605386406\n",
      "reed_acoustic_011-069-100.wav 0.03341114839659473\n",
      "flute_synthetic_000-080-050.wav 0.010369303842028554\n",
      "string_acoustic_080-049-127.wav 0.010528865958622263\n",
      "mallet_acoustic_062-093-050.wav 0.015369153580641781\n",
      "reed_acoustic_011-059-025.wav 0.03788759560703736\n",
      "organ_electronic_057-079-075.wav 0.03207958823175899\n",
      "string_acoustic_080-047-100.wav 0.030327469766432497\n",
      "mallet_acoustic_062-102-075.wav 0.01260923826187102\n",
      "reed_acoustic_011-073-075.wav 0.03660920127417855\n",
      "reed_acoustic_011-044-025.wav 0.03963718129893795\n",
      "guitar_electronic_022-054-025.wav 0.010779622655329169\n",
      "string_acoustic_080-045-050.wav 0.034132360418187596\n",
      "string_acoustic_080-044-127.wav 0.06531192925969734\n",
      "reed_acoustic_011-045-050.wav 0.03494637907280343\n"
     ]
    }
   ],
   "source": [
    "#displaying the individual errors\n",
    "errors = np.absolute(tar_test - tar_predict)\n",
    "print(errors)\n",
    "\n",
    "#displaying names of poorly predicted files\n",
    "error_threshold = 0.01\n",
    "\n",
    "print('test examples above the error_threshold')\n",
    "for index, value in errors.items():\n",
    "    if value > error_threshold: #setting an arbitrary error threshold\n",
    "        print(filenames[index], value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-up activity\n",
    "\n",
    "1. Identify the cells (as well as the lines of code within the cells) of this notebook that are absolutely necessary to train and test the regressor.\n",
    "2. Make a fair assessment of the error, explore the dymanic range/magnitude of the target values versus the magnitude of the errors (and the performance metrics).\n",
    "3. Try to use the [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to scale the features, or also the target values, assess the change in the performances. If you use the scaler on the target value, apply the inverse_transform() method of the scaler to convert the regression output to the actual traget values.\n",
    "4. Explore the same technique to predict different features used as input and/or output fo the regressor. Or experiment by changing the parameters used to compute the features, such as (sampling rate, the n_fft, hop_lenght, n_mels, etc.)\n",
    "5. Experiment by changing the hyperparameters of the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 4b: Support Vector Machine Regressor\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "This notebook includes the same regression problem of Workshop 4a, but in this case we use a more flexible (and likely powerful) [Support Vector Regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) regression technique, which is based on Support Vector Machines (SVM).\n",
    "\n",
    "Usually SVM are used for classification stasks, this [post](https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2) explains how they can be used for regression. You should also read [section 1.4.2 of the scikitlearn SVM page](http://scikit-learn.org/stable/modules/svm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "import IPython.display as Ipd\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sr = 22050\n",
    "\n",
    "#Instead of writing the code to extract the features and target value we define a function,\n",
    "#which is more elegant, it's reusable (shorter code) and makes the following code more readable.\n",
    "#For practicality, the vector features are flattenedm so that that can be stored on a row of a N-dim array\n",
    "\n",
    "#Mind that the file name is not important here because there is no label to consider (as in the previous examples)\n",
    "\n",
    "def extract_features_targets(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    \n",
    "    features = librosa.feature.melspectrogram(signal, sr=sr)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    target = np.mean(librosa.feature.rms(signal))\n",
    "    \n",
    "    return features, target\n",
    "\n",
    "\n",
    "#creating an array of zeros of the proper size where we will store computed features and lables\n",
    "filenames = os.listdir('./data/examples3')\n",
    "\n",
    "#to set the right number of columns, we call the extract_features_target() function and get the size of the features\n",
    "num_of_features = extract_features_targets('./data/examples3/'+filenames[0], sr)[0].size\n",
    "num_of_targets = extract_features_targets('./data/examples3/'+filenames[0], sr)[1].size\n",
    "features = np.zeros((len(filenames),num_of_features)) \n",
    "targets = np.zeros((len(filenames),num_of_targets))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    #print('processing',filenames[i])\n",
    "    features[i,:], targets[i,:] = extract_features_targets('./data/examples3/'+filenames[i], sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step converts the targets from a numpy array to \n",
    "#a Pandas series, which allows backtracing poorly performing examples\n",
    "#scikitlearn can handle features or targets also as Pandas formats\n",
    "#mind that this wont work with multiple target values (as the data must be dimensionless)\n",
    "targets = pd.Series(targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset in training and testing parts\n",
    "feat_train, feat_test, tar_train, tar_test = train_test_split(features, targets, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, training and testing the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVR regression object\n",
    "regr = sklearn.svm.SVR(C=1.0, epsilon=0.001, kernel='rbf')\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(feat_train, tar_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "tar_predict = regr.predict(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.0006\n",
      "Mean absolute error: 0.0166\n",
      "Max error squared error: 0.0669\n",
      "Median absolute error: 0.0101\n",
      "Coefficient of determination (R2 score): 0.8790\n",
      "Explained variance score: 0.8881\n"
     ]
    }
   ],
   "source": [
    "#computing a set of performance metrics\n",
    "\n",
    "#mean squared error (lower the better)\n",
    "print('Mean squared error: %.4f'% sklearn.metrics.mean_squared_error(tar_test, tar_predict))\n",
    "\n",
    "#mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% sklearn.metrics.mean_absolute_error(tar_test, tar_predict))\n",
    "\n",
    "#maximum error (lower the better)\n",
    "print('Max error squared error: %.4f'% sklearn.metrics.max_error(tar_test, tar_predict))\n",
    "\n",
    "#median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% sklearn.metrics.median_absolute_error(tar_test, tar_predict))\n",
    "\n",
    "#coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% sklearn.metrics.r2_score(tar_test, tar_predict))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% sklearn.metrics.explained_variance_score(tar_test, tar_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying errors and files with error above a given treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40    0.002871\n",
      "37    0.010536\n",
      "57    0.007347\n",
      "60    0.033075\n",
      "77    0.007614\n",
      "20    0.010089\n",
      "10    0.009905\n",
      "48    0.000905\n",
      "34    0.010136\n",
      "28    0.001564\n",
      "49    0.037729\n",
      "32    0.001196\n",
      "17    0.031485\n",
      "22    0.030577\n",
      "23    0.011354\n",
      "24    0.001316\n",
      "12    0.003104\n",
      "63    0.007678\n",
      "85    0.035919\n",
      "43    0.001234\n",
      "35    0.039100\n",
      "13    0.005580\n",
      "54    0.011584\n",
      "74    0.032651\n",
      "55    0.001252\n",
      "89    0.066904\n",
      "6     0.034753\n",
      "dtype: float64\n",
      "test examples above the error_threshold\n",
      "mallet_acoustic_062-096-050.wav 0.010536405454755537\n",
      "reed_acoustic_011-069-100.wav 0.03307546947202328\n",
      "flute_synthetic_000-080-050.wav 0.010089274928757191\n",
      "mallet_acoustic_062-093-050.wav 0.010136023564154106\n",
      "reed_acoustic_011-059-025.wav 0.0377291241387418\n",
      "organ_electronic_057-079-075.wav 0.03148485947770602\n",
      "string_acoustic_080-047-100.wav 0.030577421706339314\n",
      "mallet_acoustic_062-102-075.wav 0.011354338748865156\n",
      "reed_acoustic_011-073-075.wav 0.03591919042772923\n",
      "reed_acoustic_011-044-025.wav 0.03909983945175721\n",
      "guitar_electronic_022-054-025.wav 0.011584373207975784\n",
      "string_acoustic_080-045-050.wav 0.03265098864344343\n",
      "string_acoustic_080-044-127.wav 0.06690361229992264\n",
      "reed_acoustic_011-045-050.wav 0.03475349444013437\n"
     ]
    }
   ],
   "source": [
    "#displaying the individual errors\n",
    "errors = np.absolute(tar_test - tar_predict)\n",
    "print(errors)\n",
    "\n",
    "#displaying names of poorly predicted files\n",
    "error_threshold = 0.01\n",
    "\n",
    "print('test examples above the error_threshold')\n",
    "for index, value in errors.items():\n",
    "    if value > error_threshold: #setting an arbitrary error threshold\n",
    "        print(filenames[index], value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-up activity\n",
    "\n",
    "1. Change the parameters used to compute the features (mel spectrogram) and see if/how this improves the performances (e.g. change the sampling rate, the n_fft, hop_lenght, n_mels, etc.) and see if the performance improves. If performance are similar, the less feature are used the better the model is.\n",
    "2. Try to change the SVR hyperparameters and see how performance change (start from the default values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

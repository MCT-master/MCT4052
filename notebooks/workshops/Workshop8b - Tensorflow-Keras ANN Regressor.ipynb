{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 8b: Tensorflow-Keras ANN Regressor\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "This notebook shows how to train, test and use an ANN for regression in tensorflow. We use the same dataset used in earlier Workshops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Tensorflow and Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "import IPython.display as Ipd\n",
    "import os\n",
    "import sklearn\n",
    "import scipy\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# display tensorflow version (this notwbook was developed with 2.7)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing features, targets and splitting the dataset\n",
    "\n",
    "This time we store the features in an numpy array of matrices (i.e. a 3D array) ad tensorflow is able to \"flatten\" the data internally (is instructed to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sr = 44100\n",
    "\n",
    "def lin_interp_2d(data, out_size):\n",
    "    \n",
    "    x_in_size = data.shape[1]\n",
    "    y_in_size = data.shape[0]\n",
    "    x_in = np.arange(0,x_in_size)\n",
    "    y_in = np.arange(0,y_in_size)\n",
    "    interpolator = scipy.interpolate.interp2d(x_in, y_in, data, kind='linear')\n",
    "    x_out = np.arange(0,x_in_size-1,((x_in_size-1)/out_size[1]))\n",
    "    y_out = np.arange(0,y_in_size-1,((y_in_size-1)/out_size[0]))\n",
    "    output = interpolator(x_out, y_out)\n",
    "    output = output[0:out_size[0],0:out_size[1]]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def extract_features_targets(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    \n",
    "    features = librosa.feature.melspectrogram(signal, n_mels=32)\n",
    "    \n",
    "    features = lin_interp_2d(features, (32,16)) # scaling to identical lenght\n",
    "    \n",
    "    targets = np.zeros((1,2))\n",
    "    #centroid and flatness are in very sifferent ranges, they are scaled to be in a similar range (important for the loss)\n",
    "    targets[0,0] = np.mean(librosa.feature.spectral_centroid(signal))/1000 #scaling the centroid to smaller range\n",
    "    targets[0,1] = np.mean(librosa.feature.spectral_flatness(signal))*100 #scaling the flatness to larger range\n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "filenames = os.listdir('./data/examples2')\n",
    "features = np.zeros((len(filenames),32,16)) #3D Numpy array to store MFCC computed e changed if using more or less features)\n",
    "targets = np.zeros((len(filenames),2))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    features[i,:,:], targets[i,:] = extract_features_targets('./data/examples2/'+filenames[i], sr) # alternative features[i,:,:]\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the splitting we still use scikit learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset in training and testing parts\n",
    "feat_train, feat_test, tar_train, tar_test = train_test_split(features, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining, compiling, training and using the ANN\n",
    "\n",
    "Compared to the previous notebook, setting an appropriate loss function (related to the error) is a key element to train a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 512)              1025      \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,177\n",
      "Trainable params: 5,152\n",
      "Non-trainable params: 1,025\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:00:25.544745: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# building the model, the input layer must match the input data\n",
    "# for regression we need an output for each target value\n",
    "# here we also integrate a normalization layer (not an absolute must)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 16)),\n",
    "    tf.keras.layers.Normalization(),\n",
    "    tf.keras.layers.Dense(10, activation='tanh'),\n",
    "    tf.keras.layers.Dense(2, activation='relu')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting loss function and metric\n",
    "# we also specify the learning rate, which needs to be further\n",
    "# adjusted to speed up the training\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 9.6941 - val_loss: 8.4760\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5499 - val_loss: 8.3930\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.4517 - val_loss: 8.1574\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.4021 - val_loss: 8.2144\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.3649 - val_loss: 8.1164\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.3288 - val_loss: 8.0370\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2850 - val_loss: 7.9961\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.2308 - val_loss: 7.9797\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.2120 - val_loss: 7.9089\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1982 - val_loss: 7.8723\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1487 - val_loss: 7.8916\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.1141 - val_loss: 7.8562\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0953 - val_loss: 7.8260\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0628 - val_loss: 7.7422\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0318 - val_loss: 7.7669\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.0524 - val_loss: 7.7459\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0350 - val_loss: 7.7399\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.0172 - val_loss: 7.7126\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9980 - val_loss: 7.6899\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.9449 - val_loss: 7.5915\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.9105 - val_loss: 7.6301\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.8596 - val_loss: 7.7203\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.8667 - val_loss: 7.6614\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.7511 - val_loss: 7.5552\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.6556 - val_loss: 7.4850\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5874 - val_loss: 7.4752\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5430 - val_loss: 7.4706\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5026 - val_loss: 7.4718\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.4720 - val_loss: 7.4344\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.4357 - val_loss: 7.3594\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.3863 - val_loss: 7.2671\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3695 - val_loss: 7.2352\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.3439 - val_loss: 7.2140\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.2827 - val_loss: 7.2194\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.2921 - val_loss: 7.2624\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.2707 - val_loss: 7.2977\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.2298 - val_loss: 7.3780\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1733 - val_loss: 7.3055\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 8.1007 - val_loss: 7.2706\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.0628 - val_loss: 7.2045\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.0247 - val_loss: 7.1102\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.9969 - val_loss: 7.1781\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.9431 - val_loss: 7.0081\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.8971 - val_loss: 7.1000\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.8188 - val_loss: 6.9766\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7708 - val_loss: 6.8909\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.7535 - val_loss: 6.8436\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.7267 - val_loss: 6.8487\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.6666 - val_loss: 6.9245\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.6085 - val_loss: 6.9148\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 7.5974 - val_loss: 6.9062\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.5286 - val_loss: 6.9665\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.4860 - val_loss: 6.8714\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.4605 - val_loss: 6.8522\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.4141 - val_loss: 6.7725\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.3460 - val_loss: 6.6975\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.2532 - val_loss: 6.6618\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.2126 - val_loss: 6.6369\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.1740 - val_loss: 6.6111\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 7.1174 - val_loss: 6.5921\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7.0809 - val_loss: 6.5734\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.0001 - val_loss: 6.5610\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.9634 - val_loss: 6.7231\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.9058 - val_loss: 6.7086\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.8598 - val_loss: 6.6946\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8770 - val_loss: 6.6855\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.8322 - val_loss: 6.6641\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7868 - val_loss: 6.6466\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7580 - val_loss: 6.6308\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.7434 - val_loss: 6.6107\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.7544 - val_loss: 6.5249\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.6968 - val_loss: 6.5923\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.6716 - val_loss: 6.5298\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.6287 - val_loss: 6.5427\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.5955 - val_loss: 6.5360\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.5384 - val_loss: 6.3917\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.4943 - val_loss: 6.5726\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.4907 - val_loss: 6.8452\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.5083 - val_loss: 6.5798\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.3601 - val_loss: 6.5188\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3096 - val_loss: 6.5031\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2509 - val_loss: 6.4773\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.3363 - val_loss: 6.7953\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 6.5120 - val_loss: 6.9994\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.7161 - val_loss: 7.0485\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.6737 - val_loss: 6.9890\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.5422 - val_loss: 6.7870\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1722 - val_loss: 6.5249\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0782 - val_loss: 6.3417\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0814 - val_loss: 6.1369\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.0400 - val_loss: 6.1153\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9752 - val_loss: 6.1570\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0397 - val_loss: 5.8566\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0953 - val_loss: 5.5763\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.2681 - val_loss: 6.0529\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.2955 - val_loss: 5.5346\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6.1574 - val_loss: 5.8273\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.1036 - val_loss: 5.6766\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.0314 - val_loss: 6.1277\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.9829 - val_loss: 6.1495\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.9026 - val_loss: 6.1423\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.8438 - val_loss: 6.1277\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.7538 - val_loss: 6.0834\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.6499 - val_loss: 6.2212\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.6313 - val_loss: 6.2147\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.6655 - val_loss: 6.2015\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5714 - val_loss: 5.9965\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5283 - val_loss: 6.1857\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.5119 - val_loss: 6.1382\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.5016 - val_loss: 5.9076\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.3863 - val_loss: 5.9516\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.2039 - val_loss: 6.1458\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1774 - val_loss: 6.1389\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1031 - val_loss: 6.1295\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.0447 - val_loss: 6.1155\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9338 - val_loss: 6.1086\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0425 - val_loss: 5.8782\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9113 - val_loss: 6.0142\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9271 - val_loss: 6.0091\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9951 - val_loss: 6.0557\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.8895 - val_loss: 6.0472\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7978 - val_loss: 6.0206\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7325 - val_loss: 5.8336\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7263 - val_loss: 5.7848\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6828 - val_loss: 5.7783\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6126 - val_loss: 5.7498\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.5430 - val_loss: 5.7385\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5509 - val_loss: 5.7200\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.4800 - val_loss: 5.7406\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.4422 - val_loss: 5.7392\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3765 - val_loss: 5.7811\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3437 - val_loss: 5.8154\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.2830 - val_loss: 5.8344\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.2748 - val_loss: 5.7978\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2122 - val_loss: 5.7447\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2728 - val_loss: 6.0537\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.5036 - val_loss: 6.0892\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2335 - val_loss: 5.7708\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1415 - val_loss: 5.7307\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1108 - val_loss: 5.7209\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.0815 - val_loss: 5.5386\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1187 - val_loss: 5.4280\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0962 - val_loss: 5.3465\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0612 - val_loss: 5.1707\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.9698 - val_loss: 5.1669\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9729 - val_loss: 5.1486\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9113 - val_loss: 4.8137\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0087 - val_loss: 5.1215\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.9030 - val_loss: 5.0995\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8897 - val_loss: 5.0959\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8570 - val_loss: 5.1232\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8220 - val_loss: 5.2977\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7899 - val_loss: 5.2957\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7473 - val_loss: 5.2609\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.7635 - val_loss: 5.1518\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.7457 - val_loss: 5.3676\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.7448 - val_loss: 5.3883\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.7256 - val_loss: 5.4261\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.7178 - val_loss: 5.4241\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6905 - val_loss: 5.3805\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.6768 - val_loss: 5.3614\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6527 - val_loss: 5.3573\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6218 - val_loss: 5.3469\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.6138 - val_loss: 5.3358\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.6061 - val_loss: 5.3254\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5762 - val_loss: 5.1698\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5601 - val_loss: 5.1552\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.5695 - val_loss: 5.1389\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.5483 - val_loss: 5.1337\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5345 - val_loss: 5.2868\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5070 - val_loss: 5.2818\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4833 - val_loss: 5.2955\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5077 - val_loss: 5.2970\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4774 - val_loss: 5.2766\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4646 - val_loss: 5.2708\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.4541 - val_loss: 5.2841\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4651 - val_loss: 5.2940\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.4410 - val_loss: 5.3047\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4256 - val_loss: 5.3004\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4302 - val_loss: 5.1312\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4065 - val_loss: 5.0884\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.4260 - val_loss: 5.0971\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3955 - val_loss: 5.0991\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3877 - val_loss: 5.0937\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3798 - val_loss: 5.2562\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3743 - val_loss: 5.2533\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3669 - val_loss: 5.2507\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3710 - val_loss: 5.2351\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3688 - val_loss: 5.2244\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3518 - val_loss: 5.2564\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3592 - val_loss: 5.0902\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3565 - val_loss: 5.0886\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3508 - val_loss: 5.0703\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3315 - val_loss: 5.0637\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3186 - val_loss: 5.0141\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3025 - val_loss: 4.9812\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3098 - val_loss: 4.9699\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3030 - val_loss: 4.9343\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2916 - val_loss: 4.9249\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2934 - val_loss: 4.9309\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3060 - val_loss: 4.9119\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3028 - val_loss: 4.9161\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2801 - val_loss: 4.9136\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2854 - val_loss: 4.9180\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2762 - val_loss: 4.9074\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2795 - val_loss: 4.8952\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2748 - val_loss: 4.8994\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2801 - val_loss: 4.9008\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2834 - val_loss: 4.8934\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2753 - val_loss: 4.8810\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2733 - val_loss: 4.8781\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2609 - val_loss: 5.0791\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3018 - val_loss: 4.7242\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3595 - val_loss: 4.7320\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.3419 - val_loss: 4.7135\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2668 - val_loss: 5.0147\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2625 - val_loss: 4.7305\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2600 - val_loss: 4.7080\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2554 - val_loss: 4.6790\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2529 - val_loss: 4.6637\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2539 - val_loss: 4.6781\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2456 - val_loss: 4.6769\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2431 - val_loss: 4.6751\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2405 - val_loss: 4.6822\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2395 - val_loss: 4.6706\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2392 - val_loss: 4.6773\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2451 - val_loss: 4.6663\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2373 - val_loss: 4.6427\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2441 - val_loss: 4.6585\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2371 - val_loss: 4.6678\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2447 - val_loss: 4.6348\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2377 - val_loss: 4.6332\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2405 - val_loss: 4.6563\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2416 - val_loss: 4.6466\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2379 - val_loss: 4.6542\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2366 - val_loss: 4.6797\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2469 - val_loss: 4.6850\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2291 - val_loss: 4.6454\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2353 - val_loss: 4.6777\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2370 - val_loss: 4.6855\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2303 - val_loss: 4.6639\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2257 - val_loss: 4.6799\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2314 - val_loss: 4.6838\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2302 - val_loss: 4.6570\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2223 - val_loss: 4.6508\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2645 - val_loss: 4.6692\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3148 - val_loss: 4.6439\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3073 - val_loss: 4.6507\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3125 - val_loss: 4.6388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3080 - val_loss: 4.6407\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2648 - val_loss: 4.6571\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2653 - val_loss: 4.6325\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2483 - val_loss: 4.6208\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2359 - val_loss: 4.6503\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2330 - val_loss: 4.6385\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2362 - val_loss: 4.6232\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2464 - val_loss: 4.6583\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2350 - val_loss: 4.6852\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2363 - val_loss: 4.6899\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2263 - val_loss: 4.6635\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2301 - val_loss: 4.6822\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2235 - val_loss: 4.6913\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2276 - val_loss: 4.6829\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2251 - val_loss: 4.6840\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2239 - val_loss: 4.6613\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2228 - val_loss: 4.6661\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2200 - val_loss: 4.6636\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2195 - val_loss: 4.6720\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2189 - val_loss: 4.6633\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2102 - val_loss: 4.6631\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2144 - val_loss: 4.6687\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2126 - val_loss: 4.6526\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2183 - val_loss: 4.6608\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2151 - val_loss: 4.6618\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2154 - val_loss: 4.6442\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2133 - val_loss: 4.6661\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2294 - val_loss: 4.6596\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2164 - val_loss: 4.6365\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2108 - val_loss: 4.6582\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2111 - val_loss: 4.6448\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2104 - val_loss: 4.6529\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2163 - val_loss: 4.6464\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2148 - val_loss: 4.6516\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2102 - val_loss: 4.6423\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2127 - val_loss: 4.6602\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2189 - val_loss: 4.6577\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2102 - val_loss: 4.6405\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.2129 - val_loss: 4.6444\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2101 - val_loss: 4.6375\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2093 - val_loss: 4.6321\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2092 - val_loss: 4.6609\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2128 - val_loss: 4.6559\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2037 - val_loss: 4.6438\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2027 - val_loss: 4.6309\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2029 - val_loss: 4.6337\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2045 - val_loss: 4.6316\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2093 - val_loss: 4.6236\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2102 - val_loss: 4.6364\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2049 - val_loss: 4.6208\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2050 - val_loss: 4.6194\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2097 - val_loss: 4.6320\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2070 - val_loss: 4.6049\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2087 - val_loss: 4.6248\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2182 - val_loss: 4.6426\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2077 - val_loss: 4.6040\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2160 - val_loss: 4.6008\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2067 - val_loss: 4.6361\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2152 - val_loss: 4.6260\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2068 - val_loss: 4.6000\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2051 - val_loss: 4.6071\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2076 - val_loss: 4.6041\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2008 - val_loss: 4.5975\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2033 - val_loss: 4.6288\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2125 - val_loss: 4.6203\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2004 - val_loss: 4.5981\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2127 - val_loss: 4.6185\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2052 - val_loss: 4.6249\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2031 - val_loss: 4.5964\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2078 - val_loss: 4.6069\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2047 - val_loss: 4.6055\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2037 - val_loss: 4.5913\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2018 - val_loss: 4.6014\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2077 - val_loss: 4.6012\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2018 - val_loss: 4.6023\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1994 - val_loss: 4.6006\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2012 - val_loss: 4.6044\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2015 - val_loss: 4.5961\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1969 - val_loss: 4.5994\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2037 - val_loss: 4.6019\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2028 - val_loss: 4.6107\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2048 - val_loss: 4.5991\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2000 - val_loss: 4.6041\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1994 - val_loss: 4.5872\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1997 - val_loss: 4.5891\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1965 - val_loss: 4.5904\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1996 - val_loss: 4.5989\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2025 - val_loss: 4.5946\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2006 - val_loss: 4.6015\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2039 - val_loss: 4.5771\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2015 - val_loss: 4.5922\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2024 - val_loss: 4.5855\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1963 - val_loss: 4.5781\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1949 - val_loss: 4.5964\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2047 - val_loss: 4.5964\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2002 - val_loss: 4.5828\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2046 - val_loss: 4.6192\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2174 - val_loss: 4.6134\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2020 - val_loss: 4.5794\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2152 - val_loss: 4.5832\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2021 - val_loss: 4.5945\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1981 - val_loss: 4.5683\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2052 - val_loss: 4.5685\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2034 - val_loss: 4.5774\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2061 - val_loss: 4.5778\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2039 - val_loss: 4.5827\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2025 - val_loss: 4.5737\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2031 - val_loss: 4.5944\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2071 - val_loss: 4.5672\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2052 - val_loss: 4.5773\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2068 - val_loss: 4.5697\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.2007 - val_loss: 4.5578\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2024 - val_loss: 4.5857\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.2088 - val_loss: 4.5780\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2034 - val_loss: 4.5650\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2052 - val_loss: 4.5820\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2095 - val_loss: 4.5719\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1992 - val_loss: 4.5635\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2000 - val_loss: 4.5654\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2036 - val_loss: 4.5668\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2054 - val_loss: 4.5740\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2064 - val_loss: 4.5875\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2056 - val_loss: 4.5668\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2053 - val_loss: 4.5691\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2055 - val_loss: 4.5770\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2036 - val_loss: 4.5517\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2036 - val_loss: 4.5697\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1976 - val_loss: 4.5757\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1996 - val_loss: 4.5698\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1989 - val_loss: 4.5626\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1978 - val_loss: 4.5460\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2027 - val_loss: 4.5778\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2083 - val_loss: 4.5731\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2011 - val_loss: 4.5492\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2074 - val_loss: 4.5768\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2193 - val_loss: 4.5897\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2082 - val_loss: 4.5482\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2288 - val_loss: 4.5384\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2163 - val_loss: 4.5809\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.2064 - val_loss: 4.5610\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2087 - val_loss: 4.5711\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2026 - val_loss: 4.5722\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1987 - val_loss: 4.5510\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2013 - val_loss: 4.5679\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1992 - val_loss: 4.5521\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2046 - val_loss: 4.5738\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2134 - val_loss: 4.5799\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2151 - val_loss: 4.5446\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1998 - val_loss: 4.5723\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2154 - val_loss: 4.5728\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2056 - val_loss: 4.5010\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2079 - val_loss: 4.5382\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2138 - val_loss: 4.5438\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2049 - val_loss: 4.5080\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2002 - val_loss: 4.5103\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2027 - val_loss: 4.5080\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1988 - val_loss: 4.4954\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2025 - val_loss: 4.5312\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2082 - val_loss: 4.5387\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1990 - val_loss: 4.5483\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2034 - val_loss: 4.5640\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2027 - val_loss: 4.5460\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2032 - val_loss: 4.5282\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2049 - val_loss: 4.5582\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2040 - val_loss: 4.5486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2027 - val_loss: 4.5500\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1972 - val_loss: 4.5704\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1982 - val_loss: 4.5445\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1995 - val_loss: 4.5455\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1977 - val_loss: 4.5432\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1986 - val_loss: 4.5122\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2117 - val_loss: 4.5062\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2048 - val_loss: 4.4997\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1981 - val_loss: 4.4973\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1988 - val_loss: 4.5226\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2016 - val_loss: 4.4732\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2024 - val_loss: 4.4799\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1989 - val_loss: 4.4666\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1982 - val_loss: 4.4639\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1971 - val_loss: 4.4926\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2039 - val_loss: 4.4690\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2072 - val_loss: 4.4821\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2020 - val_loss: 4.4980\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2073 - val_loss: 4.4767\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1985 - val_loss: 4.5110\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2128 - val_loss: 4.4969\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2067 - val_loss: 4.4643\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2037 - val_loss: 4.4752\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2054 - val_loss: 4.4596\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2023 - val_loss: 4.4483\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1950 - val_loss: 4.4616\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1930 - val_loss: 4.4478\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1922 - val_loss: 4.4544\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1909 - val_loss: 4.4543\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2130 - val_loss: 4.4302\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1977 - val_loss: 4.4326\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1956 - val_loss: 4.4084\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.2020 - val_loss: 4.4169\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1968 - val_loss: 4.4158\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2056 - val_loss: 4.4162\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1957 - val_loss: 4.4083\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1934 - val_loss: 4.4142\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2192 - val_loss: 4.3964\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1969 - val_loss: 4.4042\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1933 - val_loss: 4.4205\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1946 - val_loss: 4.4328\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1891 - val_loss: 4.4409\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1949 - val_loss: 4.4190\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1929 - val_loss: 4.4101\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1920 - val_loss: 4.4296\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1906 - val_loss: 4.4341\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1918 - val_loss: 4.4294\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1880 - val_loss: 4.4189\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1888 - val_loss: 4.4397\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1901 - val_loss: 4.4273\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1890 - val_loss: 4.4445\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1951 - val_loss: 4.4336\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1987 - val_loss: 4.4137\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1930 - val_loss: 4.4429\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2087 - val_loss: 4.4359\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1991 - val_loss: 4.4144\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2063 - val_loss: 4.4179\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1975 - val_loss: 4.4372\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1995 - val_loss: 4.4382\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1937 - val_loss: 4.4225\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1987 - val_loss: 4.4370\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1933 - val_loss: 4.4396\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1966 - val_loss: 4.4200\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1906 - val_loss: 4.4451\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1979 - val_loss: 4.4417\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1938 - val_loss: 4.4245\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1938 - val_loss: 4.4422\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1976 - val_loss: 4.4433\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1936 - val_loss: 4.4369\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1924 - val_loss: 4.4399\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1945 - val_loss: 4.4298\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1967 - val_loss: 4.4295\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1966 - val_loss: 4.4312\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1840 - val_loss: 4.4320\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1874 - val_loss: 4.4318\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1901 - val_loss: 4.4368\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1884 - val_loss: 4.4220\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1922 - val_loss: 4.4180\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1855 - val_loss: 4.4393\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1887 - val_loss: 4.4424\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1876 - val_loss: 4.4343\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1854 - val_loss: 4.4242\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1848 - val_loss: 4.4212\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.1861 - val_loss: 4.4246\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1907 - val_loss: 4.4360\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.1872 - val_loss: 4.4355\n"
     ]
    }
   ],
   "source": [
    "# fitting the model and setting some parameters\n",
    "\n",
    "history = model.fit(\n",
    "    feat_train,\n",
    "    tar_train,\n",
    "    batch_size=32,\n",
    "    epochs=500,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting validation and train loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of determination (r2 score): 0.4717\n"
     ]
    }
   ],
   "source": [
    "# evaluating performance on test set\n",
    "# tensorflow provides many error-related metrics\n",
    "# but it does not provide the R2 score (but we can still use scikit learn)\n",
    "\n",
    "tar_pred = model.predict(feat_test)\n",
    "\n",
    "print('Coefficient of determination (r2 score): %.4f'% sklearn.metrics.r2_score(tar_test, tar_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Follow up activities\n",
    "\n",
    "1. Try to improve performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

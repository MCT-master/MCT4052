{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 6g: Parameter Estimation with Grid Search\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "Most ML models present a variety of parameters that can be tuned aming to improve performances. The object [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) allows to systematically explore a large space of parameter combinations for supervised machine learning (i.e. classification and regression tasks, where we have a well defined performance metric).\n",
    "\n",
    "Grid search works best when combined with a pipeline and righ repeated k-fold cross validation, which allows to truly assess the performances of the overall ML system. Mind that grid search can be very time consuming, especially when combined tih repeated k-fold. Therefore, it's recommendable to perform multiple small searches aiming at progressively focusing on a parameters subspace which is likely to provide the best performances. Indeed, after obtaining the first result, you can further narrow down your search in a smaller, but more specific parameters range.\n",
    "\n",
    "In this notebook first we apply grid search to a classifier only, then we repeat the process on an entire pipeline. Generally, most tunable parameters belong to the classifier (or regressor).\n",
    "\n",
    "The image below provide an overall illustration on how cross validation and grid search allows to find best parameters that later can be used to deploy a ML-based system for real-world applications.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" alt=\"drawing\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sr = 22050\n",
    "\n",
    "def extract_features(filename, sr):\n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    output = np.mean(librosa.feature.mfcc(signal, n_mfcc=20), axis=1)\n",
    "    return output\n",
    "\n",
    "\n",
    "filenames = os.listdir('./data/examples2')\n",
    "features = np.zeros((len(filenames),20))\n",
    "labels = np.zeros((len(filenames))) \n",
    "classes = ['kick','snare','cymbal','clap']\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    features[i,:] = extract_features('./data/examples2/'+filenames[i], sr)\n",
    "    if filenames[i].find('kick') != -1:\n",
    "        labels[i] = 0\n",
    "    elif filenames[i].find('snare') != -1:\n",
    "        labels[i] = 1\n",
    "    elif filenames[i].find('cymbal') != -1:\n",
    "        labels[i] = 2\n",
    "    elif filenames[i].find('clap') != -1:\n",
    "        labels[i] = 3\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grid search with cross validation and repeated stratified k-fold on classifier\n",
    "\n",
    "Mind that this code will train the SVM classifier 18000 times. It will take some time but not too much given the small size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best set of parameters {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "associated best score 0.8903077603596954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#creating classifier without parameters\n",
    "svm = SVC()\n",
    "\n",
    "#creating the repeated stratified k-folds\n",
    "#this is not a must, we can do grid search with a simple k-fold\n",
    "#cross validation by setting cv= to a number in the GridSearchCV constructor\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=100)\n",
    "\n",
    "#defining the parameters range to explore\n",
    "grid_param = {\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
    "    'gamma': [1e-2, 1e-3, 1e-4],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=svm,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='f1_macro', #this can be changes to accuracy, f1_micro, etc. or to another classification metric\n",
    "                     cv=rkf, # if you do not want to do repeated kfold, you can set cv=5 to test just on 5 different splits \n",
    "                     n_jobs=-1) #if equal to -1 will use as many CPU as available\n",
    "\n",
    "gd_sr.fit(features, labels) #performing the search\n",
    "\n",
    "print('best set of parameters', gd_sr.best_params_)\n",
    "print('associated best score',gd_sr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Grid search with cross validation and repeated stratified k-fold on a complete pipeline\n",
    "\n",
    "Mind that this code will train the pipeline (Scaler-LDA-ANN) classifier 800 times. It will take some time but not too much given the small size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best set of parameters {'classifier__activation': 'relu', 'classifier__hidden_layer_sizes': (20, 5), 'dim_red__n_components': 3}\n",
      "associated best score 0.8985411421625666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "#creating pipeline\n",
    "#note that here we do not initialize the parameters we want to tune/change\n",
    "#the parameters that we decide to initialize here will be fixed across the grid search\n",
    "#we also need to keep track of the names (between the quotes)\n",
    "#that we selected for the different components of the pipeline\n",
    "#the names are needed when creating the grid of parameters\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', LinearDiscriminantAnalysis()),\n",
    "        ('classifier', MLPClassifier(max_iter=10000))\n",
    "        ])\n",
    "\n",
    "#n_components = 10\n",
    "#hidden_layer_sizes=(20,5), max_iter=10000, activation='relu'\n",
    "\n",
    "\n",
    "#creating the repeated stratified k-folds\n",
    "#this is not a must, we can do grid search with a simple k-fold\n",
    "#cross validation by setting cv= to a number in the GridSearchCV constructor\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=20)\n",
    "\n",
    "\n",
    "#defining the parameters range to explore\n",
    "#the name of the parameters is preceeded by the name of the component\n",
    "#in the pipeline followed by two underscore\n",
    "#if you have trouble in identifying the correct, print all parameters and their\n",
    "#names uwith the following commented line\n",
    "#print(pipe.get_params().keys())\n",
    "grid_param = {\n",
    "    'dim_red__n_components': [3, 2],\n",
    "    'classifier__hidden_layer_sizes': [(20,5), (6,5,4)],\n",
    "    'classifier__activation': ['tanh', 'relu']\n",
    "}\n",
    "\n",
    "gd_sr = GridSearchCV(estimator=pipe,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='f1_macro', #this can be changes to accuracy, f1_micro, etc. or to another classification metric\n",
    "                     cv=rkf, # if you do not want to do repeated kfold, you can set cv=5 to test just on 5 different splits \n",
    "                     n_jobs=-1) #if equal to -1 will use as many CPU as available\n",
    "\n",
    "gd_sr.fit(features, labels) #performing the search\n",
    "\n",
    "print('best set of parameters', gd_sr.best_params_)\n",
    "print('associated best score',gd_sr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Follow up activity\n",
    "\n",
    "Use grid search to optimize a ML application you previously developed using your own database. Aim at improving the performances you previously obtained. It is recommended to use pipelines. When doing this, estimate how many times your grid search + CV will train and test the ML model (i.e. the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

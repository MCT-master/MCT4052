{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 6e: K-Fold Cross Validation\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "In this notebook we use the K-Fold cross validation to provide a more fair evaluation of the performances of a supervised machine learning model. More methodological information on cross-validation are available [here](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n",
    "\n",
    "The [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) object in scikit-learn facilitates the creation of K-Fold train/test split to perform the cross-validation manually and perhaps perform a deeper analysis of performances (e.g. analyze what is going wrong at each time).\n",
    "\n",
    "Instead, in this example we use use the [cross-validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) object which performs the K-Fold train/test splitting internally and provide us only with performance metrics (and additional computational info such as the training time).\n",
    "\n",
    "For more information on the possible scoring parameters that cross-valudate can compute, refer to this [page](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
    "\n",
    "Keep in mind that when using the [cross-validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) all scores follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as neg_mean_squared_error which return the negated value of the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 different classes: ['cello', 'guitar', 'clarinet', 'flute', 'harmonica']\n",
      "number of files in database 60\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and extracting features\n",
    "metadata = pd.read_csv('./data/examples4/meta.csv')\n",
    "classes = list(metadata.label.unique())\n",
    "print('There are',len(classes),'different classes:',classes)\n",
    "\n",
    "sr = 22050\n",
    "\n",
    "def extract_features(filename, sr):\n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    output = np.mean(librosa.feature.mfcc(y=signal, n_mfcc=20), axis=1)\n",
    "    return output\n",
    "\n",
    "print('number of files in database',len(metadata.index))\n",
    "features = np.zeros((len(metadata.index),20))\n",
    "labels = np.zeros((len(metadata.index)))\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "    features[i,:] = extract_features('./data/examples4/'+row['filename'], sr=sr)\n",
    "    labels[i] = (classes.index(row['label']))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Applying cross validation to a classifier\n",
    "In this example we simply show how to use the vross_validate object to a classifier. We havent scaled the features (ANN should able to handle that). Note that we pass the entire set of features/labels, the splitting happens internally. We only specify the number of folds (i.e. cv).\n",
    "\n",
    "Besises listing the score details, we also compute and display the average (mean) which is a measure of the system performances and the variance, which when small, give us a measure of the reliability of the performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.05770612, 0.00624299, 0.25861502, 0.17520595, 0.00495076]), 'score_time': array([0.00083613, 0.00043797, 0.00052714, 0.00050807, 0.0004971 ]), 'test_f1_macro': array([0.07272727, 0.08571429, 0.52666667, 0.42666667, 0.        ]), 'train_f1_macro': array([0.26329932, 0.06545455, 0.89295264, 0.95595238, 0.125     ]), 'test_accuracy': array([0.16666667, 0.25      , 0.58333333, 0.41666667, 0.        ]), 'train_accuracy': array([0.33333333, 0.1875    , 0.89583333, 0.95833333, 0.20833333])} \n",
      "\n",
      "Accuracy mean and variance 0.2833333333333333 0.04055555555555555 \n",
      "\n",
      "F1 macro mean and variance 0.22235497835497836 0.04496994703997301 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#creating classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,5), max_iter=10000, activation='relu')\n",
    "\n",
    "#initializing and running the cross validator with classifier, features, labels, scores, and number of splits\n",
    "#with cv=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#common value of cv (which is the k of k-fold) are 3 to 10, or the size of dataset per class\n",
    "#(i.e. leaving only one sample out) when the dataset is homogeneous (same number of samples per class)\n",
    "scores = sklearn.model_selection.cross_validate(mlp, features, labels, cv=5,scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Applying cross validation to a pipeline\n",
    "Since the train/test split is done internally in the cross validator we also need to pack all object that should be trained and evaluated with the same train/test split. Pipelines are essential tools for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.10667634, 0.10676718, 0.1803472 , 0.10845804, 0.10369992]), 'score_time': array([0.00058675, 0.00070286, 0.00060892, 0.00060391, 0.00058508]), 'test_f1_macro': array([0.56      , 0.75333333, 0.58666667, 0.72666667, 0.72666667]), 'train_f1_macro': array([1.        , 0.97994987, 1.        , 1.        , 1.        ]), 'test_accuracy': array([0.58333333, 0.75      , 0.66666667, 0.75      , 0.75      ]), 'train_accuracy': array([1.        , 0.97916667, 1.        , 1.        , 1.        ])} \n",
      "\n",
      "Accuracy mean and variance 0.7 0.004444444444444444 \n",
      "\n",
      "F1 macro mean and variance 0.6706666666666666 0.006481777777777779 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 10)),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(20,5), max_iter=10000, activation='relu'))\n",
    "        ])\n",
    "\n",
    "#initializing and running the cross validator with classifier, features, labels, scores, and number of splits\n",
    "#with cv=5 we partition iteratively the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#common value of cv (which is the k of k-fold) are 3 to 10, or the size of dataset per class\n",
    "#(i.e. leaving only one sample out) when the dataset is homogeneous (same number of samples per class)\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, labels, cv=5,scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Follow up activity\n",
    "\n",
    "Apply the cross validation on the pipeline you developed for the previous notebook (i.e. Workshop 6d). Try different fold values (cv) and use different scoring metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCT4052",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2d1457ce15b0056f9f79091955f3674c195692e2c003e222eb6becd54b9e41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

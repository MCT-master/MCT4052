{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 6f: Repeated K-Fold Cross Validation\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "In notebook we use the [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) and [RepeatedStratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html) to further improve the estimation of the model performances via cross validation. In particular Repeated K-Fold is likely to reduce the bias in the modelâ€™s estimated performance (although it may increase the variance) because the split in multiple time is performed randomly multiple time (and at each time a cross validation is performed). This reduced the likelyhood to have a particularly favorable split in our cross validation.\n",
    "\n",
    "Stratification is the process of rearranging the data as to ensure each fold is a good representation of the whole set. For example in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances. The repeated stratified k-fold take care of this aspect. Mind that the stratification process make sense and it can be applied only to classification problems, while the repeated k-fold object works with both classification and regression problems. \n",
    "\n",
    "In this notebook we demonstrate how to apply repeated k-fold cross validation to a regression task, and how to apply stratified repeated k-fold to a classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression task with repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and computing features\n",
    "sr = 22050\n",
    "\n",
    "def extract_features_target(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    output = librosa.feature.melspectrogram(y=signal, n_mels=25)\n",
    "    output = output.flatten()\n",
    "    \n",
    "    #preparing the output array\n",
    "    target = np.zeros((1,2))\n",
    "    target[0,0] = np.mean(librosa.feature.rms(y=signal))\n",
    "    target[0,1] = np.mean(librosa.feature.spectral_flatness(y=signal))\n",
    "    \n",
    "    return output, target\n",
    "\n",
    "filenames = os.listdir('./data/examples3')\n",
    "features = np.zeros((len(filenames),4325))\n",
    "target = np.zeros((len(filenames),2))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    features[i,:], target[i,:] = extract_features_target('./data/examples3/'+filenames[i], sr=sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.09958816, 0.11857796, 0.06680107, 0.08196497, 0.0980742 ,\n",
      "       0.07242894, 0.06333113, 0.09084606, 0.06792498, 0.1081841 ,\n",
      "       0.10718489, 0.08938599, 0.11609221, 0.08312607, 0.06014395,\n",
      "       0.10213804, 0.07937002, 0.06887603, 0.0767529 , 0.08306408,\n",
      "       0.08760786, 0.09593391, 0.09061193, 0.10667205, 0.09140992,\n",
      "       0.0826292 , 0.0798018 , 0.09002018, 0.12793803, 0.1116991 ,\n",
      "       0.07158327, 0.09427714, 0.0783298 , 0.09697104, 0.07796669,\n",
      "       0.11867189, 0.07640576, 0.10308766, 0.07693791, 0.09120703,\n",
      "       0.11785007, 0.07044935, 0.10144496, 0.09703183, 0.09077883,\n",
      "       0.07322598, 0.12408805, 0.08609271, 0.08992219, 0.08427501]), 'score_time': array([0.00256801, 0.00114608, 0.00145912, 0.00135779, 0.001127  ,\n",
      "       0.00135684, 0.00134516, 0.00105596, 0.00114608, 0.00103998,\n",
      "       0.00150919, 0.00216222, 0.00144792, 0.00262475, 0.00130987,\n",
      "       0.00115108, 0.00246811, 0.00136495, 0.00120187, 0.00153708,\n",
      "       0.00175905, 0.00629878, 0.00166702, 0.0020628 , 0.00194883,\n",
      "       0.00683975, 0.00111628, 0.00208378, 0.00163817, 0.00158095,\n",
      "       0.00245404, 0.001405  , 0.00122595, 0.00138497, 0.00877738,\n",
      "       0.00341296, 0.00142217, 0.00195408, 0.00137401, 0.00272012,\n",
      "       0.00286174, 0.00386477, 0.00257325, 0.00126815, 0.00103712,\n",
      "       0.00144386, 0.00177217, 0.00311899, 0.00180507, 0.00140786]), 'test_r2': array([ -1.89554616,  -2.82148079,  -1.61473631,  -1.17368475,\n",
      "        -2.51446032,  -1.51131817,  -0.28403119,  -9.53124878,\n",
      "        -6.11726005,  -2.84725025, -12.67507745, -13.89627623,\n",
      "        -4.08294207,  -0.66555718,  -0.67527165, -16.21828376,\n",
      "        -1.916992  , -12.34476617,  -1.27575006,  -4.20699012,\n",
      "        -9.81267295,  -2.14017729,  -0.5546451 ,  -1.21921248,\n",
      "        -6.3834218 ,  -3.13498574,  -0.33411827,  -0.32276258,\n",
      "       -11.7428694 ,  -2.48276657,  -8.04838629,  -9.41445394,\n",
      "        -1.76844737,  -2.63715944,  -6.24237987,  -6.68131105,\n",
      "        -2.00138897,  -6.78801039,  -9.52885296,  -1.91907314,\n",
      "        -6.16803333,  -1.16292181,  -2.59556688,  -3.02801344,\n",
      "       -10.41412686,  -1.72280342,  -5.40841609,  -0.06218234,\n",
      "        -2.55641414,  -1.61252709]), 'train_r2': array([-6.72462704e-01, -1.39853904e+00, -7.00450111e-01, -1.08239302e-01,\n",
      "       -9.81739276e-01, -3.95514005e-02, -5.27587931e-01, -1.27579341e+00,\n",
      "       -7.25712866e-01, -1.11627493e+00, -5.55851829e-01, -1.39206537e+00,\n",
      "        4.90007705e-02, -4.23613743e-01,  5.42087791e-03, -4.58530168e-01,\n",
      "        1.48593687e-01, -7.79250848e-01, -1.60052170e-01, -1.78173574e-01,\n",
      "       -1.86912907e+00, -4.82120282e-01, -4.24821902e-01, -3.43476038e-01,\n",
      "       -2.19322868e+00, -1.99607609e+00, -4.20300774e-01, -1.14499608e+00,\n",
      "       -1.21325895e+00, -6.91638637e-01, -7.80957441e-01, -1.33464586e+00,\n",
      "       -5.58439045e-01, -9.48051180e-01, -1.84983691e+00, -1.27771522e+00,\n",
      "       -8.39745469e-01, -1.61460298e+00, -6.25880798e+00, -5.24485163e-01,\n",
      "       -9.51619840e-01, -5.81270279e-02,  7.26777636e-04, -2.77309985e-01,\n",
      "       -1.62889715e+00, -1.62411171e+00, -1.28791496e+00, -1.32979607e-01,\n",
      "       -5.90050957e-01, -1.65412702e+00]), 'test_neg_mean_squared_error': array([-0.0241533 , -0.04102623, -0.03403506, -0.02713135, -0.04134128,\n",
      "       -0.02344223, -0.01305492, -0.09081411, -0.0510632 , -0.03829594,\n",
      "       -0.07256447, -0.08929371, -0.09949915, -0.06557836, -0.01331199,\n",
      "       -0.1376347 , -0.03671239, -0.05616901, -0.05505278, -0.05731512,\n",
      "       -0.05225961, -0.03610642, -0.02876796, -0.0494547 , -0.04278644,\n",
      "       -0.03645173, -0.03005843, -0.02880848, -0.10098434, -0.05329796,\n",
      "       -0.04965923, -0.07995387, -0.03590888, -0.03499583, -0.05681058,\n",
      "       -0.03244921, -0.04049598, -0.06309165, -0.09953302, -0.04474093,\n",
      "       -0.03871256, -0.02910126, -0.03998411, -0.04369722, -0.09753346,\n",
      "       -0.05966072, -0.03340065, -0.02738421, -0.02904892, -0.0429912 ]), 'train_neg_mean_squared_error': array([-0.02377913, -0.02374621, -0.01760111, -0.02286347, -0.02732409,\n",
      "       -0.02029551, -0.01835507, -0.02175578, -0.01460819, -0.0303886 ,\n",
      "       -0.03069376, -0.02655004, -0.02325329, -0.01966231, -0.0100216 ,\n",
      "       -0.02843629, -0.01260486, -0.02336741, -0.0186849 , -0.01491536,\n",
      "       -0.04434877, -0.02201431, -0.02339477, -0.01945899, -0.02724692,\n",
      "       -0.01992554, -0.02112096, -0.02434575, -0.03252473, -0.02243678,\n",
      "       -0.02262318, -0.02420734, -0.02686454, -0.02256472, -0.02230434,\n",
      "       -0.02810102, -0.02206233, -0.02069334, -0.04869465, -0.02496176,\n",
      "       -0.0273867 , -0.01807736, -0.01423475, -0.0150647 , -0.02545824,\n",
      "       -0.03228538, -0.02356999, -0.02936737, -0.01764552, -0.0248843 ])} \n",
      "\n",
      "MSE mean and variance -0.05011237731310939 0.00065265393524517 \n",
      "\n",
      "R2 mean and variance -4.523140489810197 16.83421378150004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 5)),\n",
    "        ('classifier', MLPRegressor(hidden_layer_sizes=(12,8,4), max_iter=2000, activation='tanh'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing the cross validator with pipe, features, target, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, target, cv=rkf, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "\n",
    "print('MSE mean and variance', np.mean(scores['test_neg_mean_squared_error']),np.var(scores['test_neg_mean_squared_error']),'\\n')\n",
    "print('R2 mean and variance', np.mean(scores['test_r2']),np.var(scores['test_r2']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification task with stratified repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 different classes: ['cello', 'guitar', 'clarinet', 'flute', 'harmonica']\n",
      "number of files in database 60\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and extracting features\n",
    "metadata = pd.read_csv('./data/examples4/meta.csv')\n",
    "classes = list(metadata.label.unique())\n",
    "print('There are',len(classes),'different classes:',classes)\n",
    "\n",
    "sr = 22050\n",
    "\n",
    "def extract_features(filename, sr):\n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    output = np.mean(librosa.feature.mfcc(y=signal, n_mfcc=20), axis=1)\n",
    "    return output\n",
    "\n",
    "print('number of files in database',len(metadata.index))\n",
    "features = np.zeros((len(metadata.index),20))\n",
    "labels = np.zeros((len(metadata.index)))\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "    features[i,:] = extract_features('./data/examples4/'+row['filename'], sr=sr)\n",
    "    labels[i] = (classes.index(row['label']))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.10126209, 0.12444115, 0.09971666, 0.12416816, 0.10993004,\n",
      "       0.10632396, 0.20066309, 0.14769721, 0.09562993, 0.09040999,\n",
      "       0.16533303, 0.14000702, 0.090801  , 0.09310818, 0.095433  ,\n",
      "       0.12820911, 0.14157891, 0.09063315, 0.16104221, 0.09823465,\n",
      "       0.09812093, 0.10025096, 0.1282618 , 0.085078  , 0.0940249 ,\n",
      "       0.11311579, 0.11833191, 0.10253   , 0.09027982, 0.21474314,\n",
      "       0.11411381, 0.09425783, 0.11598301, 0.10563993, 0.08994269,\n",
      "       0.16752005, 0.08140182, 0.12022901, 0.19190788, 0.12961197,\n",
      "       0.09372711, 0.09198117, 0.08530688, 0.14935994, 0.10778403,\n",
      "       0.11158705, 0.11296797, 0.13934612, 0.16433215, 0.14914298]), 'score_time': array([0.00067091, 0.00056911, 0.00059819, 0.00061798, 0.00061607,\n",
      "       0.0005641 , 0.00059271, 0.0005939 , 0.00058508, 0.00059891,\n",
      "       0.00061488, 0.00061512, 0.00057292, 0.00060081, 0.00060201,\n",
      "       0.00057197, 0.00060701, 0.00058103, 0.00058103, 0.00054932,\n",
      "       0.00057101, 0.00058103, 0.00059009, 0.00058508, 0.00059295,\n",
      "       0.00059104, 0.00057316, 0.00061011, 0.0005939 , 0.00057793,\n",
      "       0.00055504, 0.00056911, 0.0007019 , 0.00057817, 0.00058627,\n",
      "       0.00059891, 0.00053596, 0.00061011, 0.00055814, 0.00057197,\n",
      "       0.00060487, 0.00058079, 0.00061893, 0.00059605, 0.00059605,\n",
      "       0.00057507, 0.00057006, 0.00061297, 0.00056887, 0.00062013]), 'test_f1_macro': array([0.82      , 0.55142857, 0.77428571, 0.54      , 0.77428571,\n",
      "       0.71      , 0.57      , 0.59428571, 0.73333333, 0.54095238,\n",
      "       0.72666667, 0.48333333, 0.55333333, 0.74      , 0.54761905,\n",
      "       0.92      , 0.59333333, 0.76      , 0.65      , 1.        ,\n",
      "       0.83333333, 0.73809524, 0.74666667, 0.56      , 1.        ,\n",
      "       0.70952381, 0.81666667, 0.50761905, 0.36095238, 0.79809524,\n",
      "       0.5       , 0.82666667, 0.9047619 , 0.60761905, 0.52666667,\n",
      "       0.73333333, 0.82      , 0.65142857, 0.64333333, 0.31      ,\n",
      "       0.92      , 0.92      , 0.59428571, 0.38      , 0.73666667,\n",
      "       0.54761905, 0.74095238, 0.83333333, 0.81333333, 0.5647619 ]), 'train_f1_macro': array([1.        , 1.        , 0.97871148, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97894737,\n",
      "       0.95866136, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.95777778, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97994987,\n",
      "       1.        , 0.97894737, 1.        , 1.        , 1.        ,\n",
      "       0.78564103, 1.        , 0.97994987, 1.        , 0.95777778,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97871148]), 'test_accuracy': array([0.83333333, 0.58333333, 0.75      , 0.58333333, 0.75      ,\n",
      "       0.75      , 0.66666667, 0.66666667, 0.75      , 0.58333333,\n",
      "       0.75      , 0.5       , 0.58333333, 0.75      , 0.58333333,\n",
      "       0.91666667, 0.58333333, 0.75      , 0.66666667, 1.        ,\n",
      "       0.83333333, 0.75      , 0.75      , 0.58333333, 1.        ,\n",
      "       0.75      , 0.83333333, 0.5       , 0.41666667, 0.83333333,\n",
      "       0.58333333, 0.83333333, 0.91666667, 0.66666667, 0.58333333,\n",
      "       0.83333333, 0.83333333, 0.66666667, 0.75      , 0.41666667,\n",
      "       0.91666667, 0.91666667, 0.58333333, 0.41666667, 0.75      ,\n",
      "       0.58333333, 0.75      , 0.83333333, 0.83333333, 0.58333333]), 'train_accuracy': array([1.        , 1.        , 0.97916667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97916667,\n",
      "       0.95833333, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.95833333, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97916667,\n",
      "       1.        , 0.97916667, 1.        , 1.        , 1.        ,\n",
      "       0.79166667, 1.        , 0.97916667, 1.        , 0.95833333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.97916667])} \n",
      "\n",
      "Accuracy mean and variance 0.7100000000000002 0.0209 \n",
      "\n",
      "F1 macro mean and variance 0.6845714285714284 0.025344217687074826 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 10)),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(20,5), max_iter=10000, activation='relu'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated stratified k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing and running the cross validator with pipe, features, labels, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, labels, cv=rkf, scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Follow up activity\n",
    "\n",
    "Apply the repeated k fold and stretified repeated k fold to classification and regression on ML applications you previously developed using both your databases. It is recommended to use pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCT4052",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2d1457ce15b0056f9f79091955f3674c195692e2c003e222eb6becd54b9e41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

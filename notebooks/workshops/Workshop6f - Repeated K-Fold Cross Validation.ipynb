{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 6f: Repeated K-Fold Cross Validation\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "In notebook we use the [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) and [RepeatedStratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html) to further improve the estimation of the model performances via cross validation. In particular Repeated K-Fold is likely to reduce the bias in the modelâ€™s estimated performance (although it may increase the variance) because the split in multiple time is performed randomly multiple time (and at each time a cross validation is performed). This reduced the likelyhood to have a particularly favorable split in our cross validation.\n",
    "\n",
    "Stratification is the process of rearranging the data as to ensure each fold is a good representation of the whole set. For example in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances. The repeated stratified k-fold take care of this aspect. Mind that the stratification process make sense and it can be applied only to classification problems, while the repeated k-fold object works with both classification and regression problems. \n",
    "\n",
    "In this notebook we demonstrate how to apply repeated k-fold cross validation to a regression task, and how to apply stratified repeated k-fold to a classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression task with repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and computing features\n",
    "sr = 22050\n",
    "\n",
    "def extract_features_target(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    output = librosa.feature.melspectrogram(signal, n_mels=25)\n",
    "    output = output.flatten()\n",
    "    \n",
    "    #preparing the output array\n",
    "    target = np.zeros((1,2))\n",
    "    target[0,0] = np.mean(librosa.feature.rms(signal))\n",
    "    target[0,1] = np.mean(librosa.feature.spectral_flatness(signal))\n",
    "    \n",
    "    return output, target\n",
    "\n",
    "filenames = os.listdir('./data/examples3')\n",
    "features = np.zeros((len(filenames),4325))\n",
    "target = np.zeros((len(filenames),2))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    features[i,:], target[i,:] = extract_features_target('./data/examples3/'+filenames[i], sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.12645388, 0.1211071 , 0.11878514, 0.10641885, 0.12671471,\n",
      "       0.08146286, 0.11984587, 0.09941983, 0.07951522, 0.18826294,\n",
      "       0.12632489, 0.10452104, 0.11791205, 0.18685389, 0.13120508,\n",
      "       0.09590983, 0.16439605, 0.12469101, 0.11248994, 0.13349414,\n",
      "       0.12301397, 0.14514089, 0.06087685, 0.13959289, 0.16463423,\n",
      "       0.199543  , 0.13410878, 0.13277793, 0.09713197, 0.12380385,\n",
      "       0.17587876, 0.11027408, 0.16299987, 0.1875391 , 0.11559296,\n",
      "       0.06928205, 0.1168251 , 0.09419298, 0.06376886, 0.15411496,\n",
      "       0.1269381 , 0.14302468, 0.15886617, 0.08781505, 0.14927483,\n",
      "       0.13979316, 0.11556721, 0.13158011, 0.09422326, 0.08842397]), 'score_time': array([0.00260997, 0.0020988 , 0.0022409 , 0.00231791, 0.00227928,\n",
      "       0.00189209, 0.00235796, 0.00205803, 0.00188375, 0.00220108,\n",
      "       0.00269198, 0.002213  , 0.00227094, 0.00201511, 0.00203991,\n",
      "       0.00228286, 0.00190282, 0.002491  , 0.00233221, 0.00223088,\n",
      "       0.00226688, 0.00193095, 0.00227141, 0.00202394, 0.00215292,\n",
      "       0.00247121, 0.00198507, 0.00192809, 0.00194621, 0.00230908,\n",
      "       0.00193429, 0.00225616, 0.0019393 , 0.00193286, 0.00233412,\n",
      "       0.00226593, 0.00225997, 0.00230384, 0.002496  , 0.00190115,\n",
      "       0.00265098, 0.00194836, 0.00197887, 0.00210905, 0.00194502,\n",
      "       0.00190806, 0.00224209, 0.00198388, 0.00224781, 0.0022161 ]), 'test_r2': array([ -4.03536901,  -9.36597623,  -2.28873836,  -7.4955079 ,\n",
      "       -14.07916173,  -6.20192245,  -4.64841952,  -1.14495477,\n",
      "        -3.72449202,  -0.53130578,  -1.38438972,  -9.75061663,\n",
      "        -9.18199973,  -2.01568432,  -3.0317345 , -13.44904181,\n",
      "        -0.4782776 ,  -2.2186203 ,  -2.44957325, -13.41904079,\n",
      "        -3.40566578,  -5.8367114 ,  -1.72334055,  -6.5707629 ,\n",
      "        -7.87726464,  -4.60776113,  -4.60886167,  -9.6689192 ,\n",
      "        -1.85303015,   0.02454142,  -6.65057608,  -2.8050075 ,\n",
      "        -0.18322656,  -8.58009926, -16.28765043,  -2.97145191,\n",
      "       -11.59145374,  -2.28799368,  -2.68204234,  -2.99040281,\n",
      "        -2.48085123,  -6.73608481,  -8.86135987,  -0.5444375 ,\n",
      "        -7.96468744,  -8.54154583,  -4.2788035 ,  -5.20459156,\n",
      "        -0.69634985,  -6.51578238]), 'train_r2': array([-1.07090581, -2.04822392, -0.43988602, -0.98137126, -0.70139674,\n",
      "       -1.32459449, -1.79632035, -0.93153125, -1.06517641, -1.09034337,\n",
      "       -0.48496958, -0.53270489,  0.04352188, -1.42782097, -1.06229342,\n",
      "       -1.1975606 , -0.35517395, -0.65613573, -0.72523216, -0.40514744,\n",
      "       -2.81549744, -1.20939999, -0.40099793, -0.71436673, -1.79346272,\n",
      "       -0.21736386, -0.49040774, -0.51108219, -0.23877955, -0.14930159,\n",
      "       -1.41575321, -0.39268852,  0.23037407, -1.88035093, -2.02778254,\n",
      "       -0.38918874, -1.14973   , -0.47975825,  0.27302905, -0.03739669,\n",
      "       -1.12507099, -1.14208373, -2.06535762, -0.29004172, -0.76895275,\n",
      "       -0.67982834, -2.32730053, -2.16379155, -0.2842431 , -0.61928638]), 'test_neg_mean_squared_error': array([-0.03279779, -0.07592744, -0.04191511, -0.04445929, -0.15540274,\n",
      "       -0.03877648, -0.04719515, -0.02994018, -0.02430909, -0.02891236,\n",
      "       -0.0257126 , -0.07692221, -0.03196361, -0.04448708, -0.06406321,\n",
      "       -0.06425661, -0.04372055, -0.01957404, -0.06738466, -0.18949126,\n",
      "       -0.05203458, -0.0404121 , -0.04194175, -0.07253777, -0.06975828,\n",
      "       -0.09772729, -0.06364221, -0.05186698, -0.04898143, -0.01657237,\n",
      "       -0.10324602, -0.03636991, -0.037178  , -0.11571622, -0.07086772,\n",
      "       -0.03548951, -0.05949812, -0.03528828, -0.03081025, -0.03128265,\n",
      "       -0.06070557, -0.06349313, -0.05411867, -0.02501833, -0.05103725,\n",
      "       -0.09580284, -0.05387561, -0.04360009, -0.0194209 , -0.06263926]), 'train_neg_mean_squared_error': array([-0.02710946, -0.03770472, -0.02209073, -0.01837489, -0.02094051,\n",
      "       -0.02187306, -0.0283431 , -0.02237155, -0.02426734, -0.02896141,\n",
      "       -0.02039118, -0.02477546, -0.01361723, -0.02297783, -0.02300954,\n",
      "       -0.02304003, -0.02632022, -0.0199896 , -0.02644762, -0.02499297,\n",
      "       -0.0297523 , -0.02145196, -0.02141553, -0.02439509, -0.02556719,\n",
      "       -0.03086014, -0.02653504, -0.0164034 , -0.02110262, -0.01657877,\n",
      "       -0.02777774, -0.01614927, -0.01572071, -0.03063941, -0.02957306,\n",
      "       -0.01970044, -0.02421617, -0.01834424, -0.01274585, -0.02089675,\n",
      "       -0.02295207, -0.03718641, -0.02929071, -0.01311697, -0.02305792,\n",
      "       -0.02307436, -0.02869779, -0.03109125, -0.02178057, -0.01818826])} \n",
      "\n",
      "MSE mean and variance -0.055762891774403786 0.001059178961421458 \n",
      "\n",
      "R2 mean and variance -5.317540014605595 15.919297683056698 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "#creating the regressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,5), max_iter=2000, activation='tanh', verbose=False)\n",
    "\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 5)),\n",
    "        ('classifier', MLPRegressor(hidden_layer_sizes=(12,8,4), max_iter=2000, activation='tanh'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing the cross validator with pipe, features, target, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, target, cv=rkf, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "\n",
    "print('MSE mean and variance', np.mean(scores['test_neg_mean_squared_error']),np.var(scores['test_neg_mean_squared_error']),'\\n')\n",
    "print('R2 mean and variance', np.mean(scores['test_r2']),np.var(scores['test_r2']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification task with stratified repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 different classes: ['cello', 'guitar', 'clarinet', 'flute', 'harmonica']\n",
      "number of files in database 60\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and extracting features\n",
    "metadata = pd.read_csv('./data/examples4/meta.csv')\n",
    "classes = list(metadata.label.unique())\n",
    "print('There are',len(classes),'different classes:',classes)\n",
    "\n",
    "sr = 22050\n",
    "\n",
    "def extract_features(filename, sr):\n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    output = np.mean(librosa.feature.mfcc(signal, n_mfcc=20), axis=1)\n",
    "    return output\n",
    "\n",
    "print('number of files in database',len(metadata.index))\n",
    "features = np.zeros((len(metadata.index),20))\n",
    "labels = np.zeros((len(metadata.index)))\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "    features[i,:] = extract_features('./data/examples4/'+row['filename'], sr)\n",
    "    labels[i] = (classes.index(row['label']))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.29833293, 0.27563024, 0.38118505, 0.42341018, 0.35588098,\n",
      "       0.32108092, 0.3315239 , 0.32617021, 0.27452707, 0.32143998,\n",
      "       0.39589214, 0.52560091, 0.67980599, 0.30052376, 0.31691718,\n",
      "       0.32405996, 0.72586393, 0.27688193, 0.33958507, 0.30991411,\n",
      "       0.25682187, 0.26307392, 0.50258517, 0.35768199, 0.29305291,\n",
      "       0.26679111, 0.27996802, 0.37450218, 0.272686  , 0.32807922,\n",
      "       0.29201889, 0.31204128, 0.32975888, 0.32366419, 0.47866702,\n",
      "       0.27372217, 0.28692913, 0.283777  , 0.39601612, 0.31957984,\n",
      "       0.33203983, 0.30442905, 0.36724305, 0.74394274, 0.45512581,\n",
      "       0.37756014, 0.35779095, 0.33095288, 0.30791903, 0.31149197]), 'score_time': array([0.00137997, 0.00119972, 0.00134492, 0.00121808, 0.00119805,\n",
      "       0.00124216, 0.00134325, 0.00119185, 0.00145197, 0.0012362 ,\n",
      "       0.00120783, 0.00237298, 0.00124907, 0.00124002, 0.00126195,\n",
      "       0.00120425, 0.00124598, 0.00186229, 0.00126219, 0.00155973,\n",
      "       0.00121999, 0.00124288, 0.001688  , 0.00128794, 0.00125599,\n",
      "       0.00137424, 0.00138283, 0.00135875, 0.00126386, 0.00140095,\n",
      "       0.00120497, 0.00140977, 0.0011909 , 0.00120091, 0.00128889,\n",
      "       0.00120878, 0.00116992, 0.00126886, 0.00147986, 0.00123906,\n",
      "       0.00120497, 0.00128293, 0.00123787, 0.00144219, 0.00122404,\n",
      "       0.00206113, 0.00158381, 0.00131893, 0.00127578, 0.00155282]), 'test_f1_macro': array([0.60761905, 0.6447619 , 0.84333333, 0.84      , 0.76666667,\n",
      "       0.72      , 0.73142857, 1.        , 0.5547619 , 0.83142857,\n",
      "       0.85333333, 0.84333333, 0.55142857, 1.        , 0.51428571,\n",
      "       0.82      , 0.70666667, 0.58095238, 0.65333333, 0.66      ,\n",
      "       0.72666667, 0.84333333, 0.57      , 0.81333333, 0.74666667,\n",
      "       0.66761905, 0.9047619 , 0.58761905, 0.61333333, 0.73809524,\n",
      "       1.        , 0.74      , 0.76      , 0.72      , 0.51047619,\n",
      "       0.76      , 0.74      , 1.        , 0.75333333, 0.66      ,\n",
      "       0.66666667, 0.33714286, 0.92      , 0.56      , 0.66      ,\n",
      "       0.77428571, 0.89333333, 0.74333333, 0.72666667, 0.8247619 ]), 'train_f1_macro': array([1.        , 1.        , 1.        , 1.        , 0.97894737,\n",
      "       1.        , 1.        , 0.97871148, 1.        , 1.        ,\n",
      "       0.97894737, 1.        , 1.        , 1.        , 0.97871148,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.97871148, 0.95894737, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ]), 'test_accuracy': array([0.66666667, 0.66666667, 0.83333333, 0.83333333, 0.75      ,\n",
      "       0.75      , 0.75      , 1.        , 0.66666667, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.58333333, 1.        , 0.58333333,\n",
      "       0.83333333, 0.66666667, 0.66666667, 0.75      , 0.66666667,\n",
      "       0.75      , 0.83333333, 0.66666667, 0.83333333, 0.75      ,\n",
      "       0.66666667, 0.91666667, 0.58333333, 0.66666667, 0.75      ,\n",
      "       1.        , 0.75      , 0.75      , 0.75      , 0.5       ,\n",
      "       0.75      , 0.75      , 1.        , 0.75      , 0.66666667,\n",
      "       0.66666667, 0.33333333, 0.91666667, 0.58333333, 0.66666667,\n",
      "       0.75      , 0.91666667, 0.75      , 0.75      , 0.83333333]), 'train_accuracy': array([1.        , 1.        , 1.        , 1.        , 0.97916667,\n",
      "       1.        , 1.        , 0.97916667, 1.        , 1.        ,\n",
      "       0.97916667, 1.        , 1.        , 1.        , 0.97916667,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.97916667, 0.95833333, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ])} \n",
      "\n",
      "Accuracy mean and variance 0.7483333333333334 0.016525 \n",
      "\n",
      "F1 macro mean and variance 0.7336952380952382 0.01929021823129252 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 10)),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(20,5), max_iter=10000, activation='relu'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated stratified k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing and running the cross validator with pipe, features, labels, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, labels, cv=rkf, scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Follow up activity\n",
    "\n",
    "Apply the repeated k fold and stretified repeated k fold to classification and regression on ML applications you previously developed using both your databases. It is recommended to use pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

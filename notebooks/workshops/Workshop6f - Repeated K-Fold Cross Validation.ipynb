{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 6f: Repeated K-Fold Cross Validation\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "In notebook we use the [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html) and [RepeatedStratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html) to further improve the estimation of the model performances via cross validation. In particular Repeated K-Fold is likely to reduce the bias in the modelâ€™s estimated performance (although it may increase the variance) because the split in multiple time is performed randomly multiple time (and at each time a cross validation is performed). This reduced the likelyhood to have a particularly favorable split in our cross validation.\n",
    "\n",
    "Stratification is the process of rearranging the data as to ensure each fold is a good representation of the whole set. For example in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances. The repeated stratified k-fold take care of this aspect. Mind that the stratification process make sense and it can be applied only to classification problems, while the repeated k-fold object works with both classification and regression problems. \n",
    "\n",
    "In this notebook we demonstrate how to apply repeated k-fold cross validation to a regression task, and how to apply stratified repeated k-fold to a classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression task with repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and computing features\n",
    "sr = 22050\n",
    "\n",
    "def extract_features_target(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    output = librosa.feature.melspectrogram(y=signal, n_mels=25)\n",
    "    output = output.flatten()\n",
    "    \n",
    "    #preparing the output array\n",
    "    target = np.zeros((1,2))\n",
    "    target[0,0] = np.mean(librosa.feature.rms(y=signal))\n",
    "    target[0,1] = np.mean(librosa.feature.spectral_flatness(y=signal))\n",
    "    \n",
    "    return output, target\n",
    "\n",
    "filenames = os.listdir('./data/examples3')\n",
    "features = np.zeros((len(filenames),4325))\n",
    "target = np.zeros((len(filenames),2))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    features[i,:], target[i,:] = extract_features_target('./data/examples3/'+filenames[i], sr=sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.10154796, 0.10232663, 0.15194821, 0.11705613, 0.14870119,\n",
      "       0.08661199, 0.14207625, 0.09549093, 0.16779613, 0.1067152 ,\n",
      "       0.10799623, 0.09253407, 0.10906816, 0.18411088, 0.10292816,\n",
      "       0.06886029, 0.09984684, 0.11520696, 0.09330273, 0.12761188,\n",
      "       0.07633376, 0.12302423, 0.14232206, 0.24080014, 0.09807301,\n",
      "       0.17648816, 0.09733987, 0.10529518, 0.10580397, 0.139189  ,\n",
      "       0.11333609, 0.16447902, 0.0984199 , 0.15436387, 0.12027693,\n",
      "       0.11258197, 0.09731007, 0.0964129 , 0.1009872 , 0.10322523,\n",
      "       0.1542511 , 0.10777211, 0.16953707, 0.14464116, 0.12421012,\n",
      "       0.166857  , 0.07628417, 0.14685488, 0.23637509, 0.18907905]), 'score_time': array([0.00286078, 0.00272632, 0.00222898, 0.00242877, 0.00230598,\n",
      "       0.00284219, 0.00230789, 0.00283003, 0.00248694, 0.00279498,\n",
      "       0.003232  , 0.00290608, 0.00294304, 0.00227809, 0.00270081,\n",
      "       0.00269485, 0.00252128, 0.00259614, 0.00260019, 0.00253797,\n",
      "       0.00269794, 0.0028069 , 0.00237989, 0.00228715, 0.00286984,\n",
      "       0.00222278, 0.00287104, 0.00293612, 0.00279808, 0.00252724,\n",
      "       0.00282001, 0.00228715, 0.00325227, 0.00273633, 0.00294304,\n",
      "       0.00259686, 0.00304294, 0.00281501, 0.00306582, 0.0028429 ,\n",
      "       0.00247598, 0.002774  , 0.00226498, 0.00270677, 0.00284195,\n",
      "       0.00229096, 0.00277567, 0.00243521, 0.00235987, 0.00221109]), 'test_r2': array([-1.20449552e+00, -1.85366389e+01, -5.68201572e+00, -1.39679449e+00,\n",
      "       -9.97452506e+00, -1.80502913e+00, -9.10551309e-01, -3.02647162e+01,\n",
      "       -5.02757969e-01, -5.66765320e+00, -4.20223231e+00,  1.09371838e-01,\n",
      "       -4.19589837e+00, -8.21078384e+00, -2.27018566e+00, -3.80576896e-01,\n",
      "       -3.05877926e+01, -1.68001500e+00,  2.38688400e-02, -3.75364284e+00,\n",
      "       -5.98055183e+00, -5.42614017e+00, -2.36974068e+01, -9.20117230e+00,\n",
      "       -1.88980394e+00, -1.06828737e+01, -1.81982466e+00, -4.33981238e+00,\n",
      "       -4.54081320e+00, -4.99184886e-01, -5.70445698e+00, -1.99523233e+01,\n",
      "       -1.77169117e+00, -1.84381581e+00, -3.44686831e+00, -1.00230202e+01,\n",
      "       -8.11203510e-01, -4.08868684e+00, -1.55615711e+00, -9.88534265e+00,\n",
      "       -8.27267648e+00, -4.05338388e+00, -1.95913492e+00, -7.50421323e-01,\n",
      "       -4.09346770e-01, -2.10763043e+01, -4.48310189e+00, -8.00517174e+00,\n",
      "       -2.80494510e-01, -8.35865610e+00]), 'train_r2': array([-0.83366264, -0.36264284, -0.92228521, -0.84675603, -1.02318533,\n",
      "       -1.59634553, -1.20569529, -1.61139722, -0.40273747, -1.09449222,\n",
      "       -1.13081789,  0.14625078, -0.59941741, -1.84173184, -0.83739948,\n",
      "       -0.15540837, -0.09222939, -0.0419621 ,  0.29251518, -0.86188083,\n",
      "       -0.17821682, -0.57175918, -2.41330461, -3.30550771, -0.29493656,\n",
      "       -1.25184347, -0.02491973, -0.50571052, -1.05285687, -0.71321413,\n",
      "       -0.1412678 , -2.45165484, -0.29757661, -1.35767461, -1.17475369,\n",
      "       -1.1508525 , -0.26693631, -0.10750649,  0.04204615, -1.22101262,\n",
      "       -2.38859718, -0.92940627, -0.43397644,  0.23908002, -0.32999398,\n",
      "       -3.6802767 , -0.0076253 , -1.26284452, -0.27537102, -5.42059249]), 'test_neg_mean_squared_error': array([-0.05117717, -0.06719999, -0.08865404, -0.03092885, -0.03866027,\n",
      "       -0.01586686, -0.0591543 , -0.10157554, -0.02879924, -0.03807257,\n",
      "       -0.03625883, -0.012611  , -0.13853385, -0.0541467 , -0.02787967,\n",
      "       -0.03779551, -0.07569889, -0.01493114, -0.01761144, -0.06984762,\n",
      "       -0.02975064, -0.11102159, -0.11250885, -0.08936201, -0.03194745,\n",
      "       -0.03999373, -0.01162087, -0.06065286, -0.07426386, -0.0276718 ,\n",
      "       -0.03208525, -0.09974868, -0.02923108, -0.05241509, -0.12381399,\n",
      "       -0.0713298 , -0.03440112, -0.02765208, -0.02552763, -0.10250684,\n",
      "       -0.06074126, -0.04409678, -0.05453623, -0.02322905, -0.03764082,\n",
      "       -0.13388232, -0.03065746, -0.06079627, -0.03302021, -0.07596342]), 'train_neg_mean_squared_error': array([-0.01741827, -0.02038867, -0.03761089, -0.01647532, -0.02955137,\n",
      "       -0.02393508, -0.01949867, -0.02674993, -0.02191367, -0.02814354,\n",
      "       -0.01934853, -0.01375332, -0.0237709 , -0.02575635, -0.01990901,\n",
      "       -0.01312357, -0.02405721, -0.01376229, -0.0126523 , -0.0270564 ,\n",
      "       -0.01028606, -0.02186328, -0.02492922, -0.03166255, -0.01451785,\n",
      "       -0.02248993, -0.01742672, -0.03350556, -0.01646732, -0.02163385,\n",
      "       -0.02709321, -0.02652971, -0.01687478, -0.0261101 , -0.02354273,\n",
      "       -0.02365208, -0.01576163, -0.01621363, -0.02070212, -0.02262001,\n",
      "       -0.02997411, -0.01891817, -0.02276636, -0.01489864, -0.01535839,\n",
      "       -0.04182138, -0.01170504, -0.02476948, -0.01445637, -0.03801033])} \n",
      "\n",
      "MSE mean and variance -0.05494945021880269 0.0010885593083841487 \n",
      "\n",
      "R2 mean and variance -6.318058119048493 54.455599928995426 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 5)),\n",
    "        ('classifier', MLPRegressor(hidden_layer_sizes=(12,8,4), max_iter=2000, activation='tanh'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing the cross validator with pipe, features, target, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, target, cv=rkf, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "\n",
    "print('MSE mean and variance', np.mean(scores['test_neg_mean_squared_error']),np.var(scores['test_neg_mean_squared_error']),'\\n')\n",
    "print('R2 mean and variance', np.mean(scores['test_r2']),np.var(scores['test_r2']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification task with stratified repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 different classes: ['cello', 'guitar', 'clarinet', 'flute', 'harmonica']\n",
      "number of files in database 60\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#loading files and extracting features\n",
    "metadata = pd.read_csv('./data/examples4/meta.csv')\n",
    "classes = list(metadata.label.unique())\n",
    "print('There are',len(classes),'different classes:',classes)\n",
    "\n",
    "sr = 22050\n",
    "\n",
    "def extract_features(filename, sr):\n",
    "    signal, dummy = librosa.load(filename, sr=sr, mono=True)\n",
    "    output = np.mean(librosa.feature.mfcc(y=signal, n_mfcc=20), axis=1)\n",
    "    return output\n",
    "\n",
    "print('number of files in database',len(metadata.index))\n",
    "features = np.zeros((len(metadata.index),20))\n",
    "labels = np.zeros((len(metadata.index)))\n",
    "\n",
    "for i, row in metadata.iterrows():\n",
    "    features[i,:] = extract_features('./data/examples4/'+row['filename'], sr=sr)\n",
    "    labels[i] = (classes.index(row['label']))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.34852886, 0.48296809, 0.25097084, 0.23481441, 0.26952696,\n",
      "       0.23894501, 0.32500887, 0.28511   , 0.22001195, 0.28299093,\n",
      "       0.50000167, 0.31847572, 0.28933501, 0.26955795, 0.27311182,\n",
      "       0.29453897, 0.25470424, 0.21297622, 0.28232121, 0.23591304,\n",
      "       0.27149081, 0.28396797, 0.26231289, 0.31240988, 0.23313808,\n",
      "       0.28538108, 0.29141808, 0.28191113, 0.28739095, 0.28513503,\n",
      "       0.24892783, 0.29902196, 0.30431509, 0.25590205, 0.25323606,\n",
      "       0.38557696, 0.31396508, 0.20800591, 0.22099209, 0.25019383,\n",
      "       0.26580811, 0.23003507, 0.2738111 , 0.27208996, 0.39080882,\n",
      "       0.2298491 , 0.32316279, 0.25985098, 0.35246992, 0.23148084]), 'score_time': array([0.00267482, 0.00253987, 0.00216913, 0.00220799, 0.00216889,\n",
      "       0.00302529, 0.00207806, 0.00231504, 0.00221515, 0.00251794,\n",
      "       0.00212717, 0.00212121, 0.00223207, 0.00232124, 0.00210285,\n",
      "       0.00233817, 0.00213671, 0.00248098, 0.00215292, 0.00207305,\n",
      "       0.0024693 , 0.00220609, 0.00217295, 0.00214028, 0.00230098,\n",
      "       0.00219297, 0.0021069 , 0.00210929, 0.00216007, 0.00290012,\n",
      "       0.00215721, 0.00253606, 0.00215602, 0.00267696, 0.00217485,\n",
      "       0.00208592, 0.0024159 , 0.00206518, 0.00214195, 0.00205588,\n",
      "       0.00207901, 0.00246787, 0.00211287, 0.00209618, 0.00264406,\n",
      "       0.00205278, 0.00209522, 0.0021801 , 0.00245619, 0.00212121]), 'test_f1_macro': array([0.5047619 , 0.6547619 , 0.8047619 , 0.51333333, 0.57428571,\n",
      "       0.66666667, 0.66666667, 0.84      , 0.59333333, 0.50761905,\n",
      "       0.58      , 0.57904762, 0.66666667, 0.82666667, 0.81333333,\n",
      "       0.74      , 0.84      , 0.68666667, 0.84      , 0.69333333,\n",
      "       0.73666667, 0.59333333, 0.74      , 0.83333333, 0.46666667,\n",
      "       0.83142857, 0.64285714, 0.67333333, 0.71428571, 0.9047619 ,\n",
      "       0.36190476, 0.56761905, 0.8047619 , 0.67142857, 0.81333333,\n",
      "       0.36666667, 0.9047619 , 0.66666667, 0.58666667, 0.82666667,\n",
      "       1.        , 0.76      , 0.74761905, 0.63333333, 0.65      ,\n",
      "       0.73809524, 0.58      , 0.92      , 0.66666667, 0.83333333]), 'train_f1_macro': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.97894737, 0.95681818, 1.        , 0.97994987, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.97871148, 1.        , 1.        , 1.        ,\n",
      "       0.97994987, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.97994987, 1.        ,\n",
      "       1.        , 1.        , 0.91470923, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ]), 'test_accuracy': array([0.58333333, 0.75      , 0.83333333, 0.5       , 0.58333333,\n",
      "       0.66666667, 0.66666667, 0.83333333, 0.66666667, 0.5       ,\n",
      "       0.58333333, 0.66666667, 0.66666667, 0.83333333, 0.83333333,\n",
      "       0.75      , 0.83333333, 0.66666667, 0.83333333, 0.66666667,\n",
      "       0.75      , 0.58333333, 0.75      , 0.83333333, 0.5       ,\n",
      "       0.83333333, 0.75      , 0.66666667, 0.75      , 0.91666667,\n",
      "       0.5       , 0.58333333, 0.83333333, 0.75      , 0.83333333,\n",
      "       0.33333333, 0.91666667, 0.66666667, 0.58333333, 0.83333333,\n",
      "       1.        , 0.75      , 0.75      , 0.75      , 0.66666667,\n",
      "       0.75      , 0.58333333, 0.91666667, 0.66666667, 0.83333333]), 'train_accuracy': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.97916667, 0.95833333, 1.        , 0.97916667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.97916667, 1.        , 1.        , 1.        ,\n",
      "       0.97916667, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.97916667, 1.        ,\n",
      "       1.        , 1.        , 0.91666667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ])} \n",
      "\n",
      "Accuracy mean and variance 0.715 0.017247222222222223 \n",
      "\n",
      "F1 macro mean and variance 0.6965619047619047 0.018936891519274378 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#creating pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('dim_red', PCA(n_components = 10)),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(20,5), max_iter=10000, activation='relu'))\n",
    "        ])\n",
    "\n",
    "#creating the repeated stratified k-fold, use random_state to get repeatable results\n",
    "#with n_splits=5 we partition the data into 5 splits of 20% and use 4 for trainign and 1 for testing.\n",
    "#the n_repeats indicates how many times the k-fold has to be repeated\n",
    "rkf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "#initializing and running the cross validator with pipe, features, labels, scores, and kfold object\n",
    "scores = sklearn.model_selection.cross_validate(pipe, features, labels, cv=rkf, scoring=('f1_macro', 'accuracy'),return_train_score=True)\n",
    "\n",
    "print(scores,'\\n')\n",
    "print('Accuracy mean and variance', np.mean(scores['test_accuracy']),np.var(scores['test_accuracy']),'\\n')\n",
    "print('F1 macro mean and variance', np.mean(scores['test_f1_macro']),np.var(scores['test_f1_macro']),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Follow up activity\n",
    "\n",
    "Apply the repeated k fold and stretified repeated k fold to classification and regression on ML applications you previously developed using both your databases. It is recommended to use pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2d1457ce15b0056f9f79091955f3674c195692e2c003e222eb6becd54b9e41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

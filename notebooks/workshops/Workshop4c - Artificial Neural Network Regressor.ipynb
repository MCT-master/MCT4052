{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCT4052 Workshop 4c: Artificial Neural Network Regressor\n",
    "\n",
    "*Author: Stefano Fasciani, stefano.fasciani@imv.uio.no, Department of Musicology, University of Oslo.*\n",
    "\n",
    "This notebook includes the a regression problem similar to Workshop 4a and 4b, but in this case we use a more [MLP Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) to predict 2 target values.\n",
    "\n",
    "Predicting multiple quantities is possible with the MLP Regressor due to the flexibility of the the MLP Regressor architecture, which is an ANN designed to solve regression tasks. This is not possible with the regressors used in the previous notebooks. Compared to the MLP classifier, we can have at the output an arbitrary number of neurons (with fixed linear - aka identity - activation function) determined by the number of target values we try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "import IPython.display as Ipd\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sr = 22050\n",
    "\n",
    "#Instead of writing the code to extract the features and target value we define a function,\n",
    "#which is more elegant, it's reusable (shorter code) and makes the following code more readable.\n",
    "#For practicality, the vector features are flattenedm so that that can be stored on a row of a N-dim array\n",
    "\n",
    "#Mind that the file name is not important here because there is no label to consider (as in the previous examples)\n",
    "\n",
    "def extract_features_targets(filename, sr):\n",
    "    \n",
    "    signal, dummy = librosa.load(filename, sr, mono=True)\n",
    "    \n",
    "    features = librosa.feature.melspectrogram(signal, sr=sr)\n",
    "    features = features.flatten()\n",
    "    \n",
    "    #preparing the output array\n",
    "    targets = np.zeros((1,2))\n",
    "    targets[0,0] = np.mean(librosa.feature.rms(signal))\n",
    "    targets[0,1] = np.mean(librosa.feature.spectral_flatness(signal))\n",
    "    \n",
    "    return features, targets\n",
    "\n",
    "\n",
    "#creating an array of zeros of the proper size where we will store computed features and lables\n",
    "filenames = os.listdir('./data/examples3')\n",
    "\n",
    "#to set the right number of columns, we call the extract_features_target() function and get the size of the features\n",
    "num_of_features = extract_features_targets('./data/examples3/'+filenames[0], sr)[0].size\n",
    "num_of_targets = extract_features_targets('./data/examples3/'+filenames[0], sr)[1].size\n",
    "features = np.zeros((len(filenames),num_of_features)) \n",
    "targets = np.zeros((len(filenames),num_of_targets))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    #print('processing',filenames[i])\n",
    "    features[i,:], targets[i,:] = extract_features_targets('./data/examples3/'+filenames[i], sr)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#splitting the dataset in training and testing parts\n",
    "feat_train, feat_test, tar_train, tar_test = train_test_split(features, targets, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, training and testing the Multi Layer Perceptron (MLP) regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.28658285\n",
      "Iteration 2, loss = 0.89429308\n",
      "Iteration 3, loss = 0.23667829\n",
      "Iteration 4, loss = 0.07488943\n",
      "Iteration 5, loss = 0.11105800\n",
      "Iteration 6, loss = 0.11555750\n",
      "Iteration 7, loss = 0.07837200\n",
      "Iteration 8, loss = 0.04136553\n",
      "Iteration 9, loss = 0.02379202\n",
      "Iteration 10, loss = 0.02267821\n",
      "Iteration 11, loss = 0.02321554\n",
      "Iteration 12, loss = 0.02424362\n",
      "Iteration 13, loss = 0.02228101\n",
      "Iteration 14, loss = 0.01817333\n",
      "Iteration 15, loss = 0.01335206\n",
      "Iteration 16, loss = 0.00998075\n",
      "Iteration 17, loss = 0.00937392\n",
      "Iteration 18, loss = 0.00846580\n",
      "Iteration 19, loss = 0.00803868\n",
      "Iteration 20, loss = 0.00705826\n",
      "Iteration 21, loss = 0.00591790\n",
      "Iteration 22, loss = 0.00598726\n",
      "Iteration 23, loss = 0.00604251\n",
      "Iteration 24, loss = 0.00585980\n",
      "Iteration 25, loss = 0.00533294\n",
      "Iteration 26, loss = 0.00491076\n",
      "Iteration 27, loss = 0.00444436\n",
      "Iteration 28, loss = 0.00390434\n",
      "Iteration 29, loss = 0.00371426\n",
      "Iteration 30, loss = 0.00332058\n",
      "Iteration 31, loss = 0.00298438\n",
      "Iteration 32, loss = 0.00269618\n",
      "Iteration 33, loss = 0.00281355\n",
      "Iteration 34, loss = 0.00260638\n",
      "Iteration 35, loss = 0.00251222\n",
      "Iteration 36, loss = 0.00249598\n",
      "Iteration 37, loss = 0.00218500\n",
      "Iteration 38, loss = 0.00240288\n",
      "Iteration 39, loss = 0.00233012\n",
      "Iteration 40, loss = 0.00213821\n",
      "Iteration 41, loss = 0.00193403\n",
      "Iteration 42, loss = 0.00192137\n",
      "Iteration 43, loss = 0.00179747\n",
      "Iteration 44, loss = 0.00169508\n",
      "Iteration 45, loss = 0.00160897\n",
      "Iteration 46, loss = 0.00158125\n",
      "Iteration 47, loss = 0.00156270\n",
      "Iteration 48, loss = 0.00165544\n",
      "Iteration 49, loss = 0.00195096\n",
      "Iteration 50, loss = 0.00189429\n",
      "Iteration 51, loss = 0.00192309\n",
      "Iteration 52, loss = 0.00182768\n",
      "Iteration 53, loss = 0.00175109\n",
      "Iteration 54, loss = 0.00165992\n",
      "Iteration 55, loss = 0.00152993\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#Import the classifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "##Creating an instance of a MLP regressor\n",
    "#and setting it some option (max mum epoch, verbose on, activation of neurons)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(200,100,50), max_iter=200, tol=0.0001, activation='tanh', verbose=True)\n",
    "\n",
    "#train the model\n",
    "mlp.fit(feat_train, tar_train)\n",
    "\n",
    "#applying the the model on the test data (features)\n",
    "tar_pred = mlp.predict(feat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the loss curve over the training iterations and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.0287\n",
      "Mean absolute error: 0.1092\n",
      "Median absolute error: 0.0717\n",
      "Coefficient of determination (R2 score): -1.1266\n",
      "Explained variance score: -0.8968\n",
      "R2 score on individual targets [-2.39789302  0.14477944]\n"
     ]
    }
   ],
   "source": [
    "#plotting the loss curve over training iteration \n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel('iteration')\n",
    "plt.xlabel('loss')\n",
    "plt.show()\n",
    "\n",
    "#computing a set of performance metrics\n",
    "\n",
    "#mean squared error (lower the better)\n",
    "print('Mean squared error: %.4f'% sklearn.metrics.mean_squared_error(tar_test, tar_pred))\n",
    "\n",
    "#mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% sklearn.metrics.mean_absolute_error(tar_test, tar_pred))\n",
    "\n",
    "#median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% sklearn.metrics.median_absolute_error(tar_test, tar_pred))\n",
    "\n",
    "#coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% sklearn.metrics.r2_score(tar_test, tar_pred))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% sklearn.metrics.explained_variance_score(tar_test, tar_pred))\n",
    "\n",
    "#this is is a better represenation of the r2 score when working with multiple outputs\n",
    "#as it provides a value for each target value\n",
    "print('R2 score on individual targets',sklearn.metrics.r2_score(tar_test, tar_pred, multioutput='raw_values') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-up activity\n",
    "\n",
    "1. Explore the attributes of the \"mlp\" object and verify size of the network, input and output layers, and activation functions used throughout the network and at the output.\n",
    "\n",
    "2. Make a fair assessment of the error, explore the dymanic range/magnitude of the target values versus the magnitude of the errors (and the performance metrics).\n",
    "\n",
    "3. Try to change the MLP hyperparameters to see if performances can improve.\n",
    "\n",
    "4. Reduce this regression progrem to the same presented in 4a and 4b (i.e. predict RMS only). Compare the performances with the other two regressors (ensure to use the same train/test split random state).\n",
    "\n",
    "5. Use the three regressors from 4a, 4b, and 4c on your dataset (in a single notebook) and compare the performances (pick one metric only as reference). Also include also a 4th regression method from those available in [scikitlearn](https://scikit-learn.org/stable/supervised_learning.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
